{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgUhT9tErkfU","executionInfo":{"status":"ok","timestamp":1679270757924,"user_tz":-540,"elapsed":19666,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"5f556846-3b53-4db7-a2f6-fc726c5c0771"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mZXQ6Mdvf6LP","executionInfo":{"status":"ok","timestamp":1679270767712,"user_tz":-540,"elapsed":1,"user":{"displayName":"최현빈","userId":"18077309965622897468"}}},"outputs":[],"source":["!pip install -U \"tensorflow>=2.5\"\n","\n","import os\n","import pathlib\n","import time\n","import csv\n","import json\n","import xml.etree.ElementTree as ET\n","import tensorflow as tf\n","from collections import namedtuple\n","import glob\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import re\n","from shutil import copyfile\n","import argparse\n","import math\n","import random\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from six.moves.urllib.request import urlopen\n","\n","import tensorflow as tf\n","# import tensorflow_hub as hub\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# %matplotlib inline\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"vvh8DGBhgLoF","executionInfo":{"status":"ok","timestamp":1679270864264,"user_tz":-540,"elapsed":467,"user":{"displayName":"최현빈","userId":"18077309965622897468"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# tf_od API 다운로드\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone https://github.com/tensorflow/models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvmJYxhGvRAN","executionInfo":{"status":"ok","timestamp":1679270902441,"user_tz":-540,"elapsed":36234,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"df12495b-bdb6-4d83-9e0a-9ee4572d5e58"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 82261, done.\u001b[K\n","remote: Counting objects: 100% (167/167), done.\u001b[K\n","remote: Compressing objects: 100% (99/99), done.\u001b[K\n","remote: Total 82261 (delta 87), reused 143 (delta 68), pack-reused 82094\u001b[K\n","Receiving objects: 100% (82261/82261), 596.44 MiB | 18.04 MiB/s, done.\n","Resolving deltas: 100% (58722/58722), done.\n"]}]},{"cell_type":"code","source":["# coco API 설치\n","%%bash\n","sudo apt install -y protobuf-compiler\n","cd /content/models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cd /content\n","git clone https://github.com/cocodataset/cocoapi.git\n","cd /content/cocoapi/PythonAPI\n","make\n","cp -r pycocotools /content/models/research/\n","cd /content/models/research/\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","cd /content"],"metadata":{"id":"1-qXZF4rgN3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 워크스페이스 디렉토리 생성\n","%%bash\n","# mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/scripts\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/scripts/preprocessing\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/exported-models\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/images\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/annotations\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/images/test\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/images/train\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/models\"\n","mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/pre-trained-models\"\n"],"metadata":{"id":"BVApQijLgb_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/gdrive/MyDrive/da/scripts/preprocessing/make_tfrecord.py\" \\\n","\"/content/gdrive/MyDrive/Team.B_Project/scripts/preprocessing/make_tfrecord.py\""],"metadata":{"id":"2sNPKinkuaBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 디렉토리 생성 및 해당 경로에 데이터셋 다운로드\n","!mkdir \"/content/gdrive/MyDrive/datasets/\"\n","!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar -P \"/content/gdrive/MyDrive/datasets/\""],"metadata":{"id":"-uu422Wqg0QC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 현재 working 디렉토리에 복사 및 묶음 해제\n","!cp \"/content/gdrive/MyDrive/datasets/VOCtrainval_11-May-2012.tar\" ./\n","!tar -xvf ./VOCtrainval_11-May-2012.tar"],"metadata":{"id":"UwMYpM5ghLy4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D77L2Y0bHCaN","executionInfo":{"status":"ok","timestamp":1679015300991,"user_tz":-540,"elapsed":4,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"800bdbf9-bdd5-4858-a424-566cddd5c17f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# 해당 경로로 이동 후 파일 갯수 확인\n","%cd ./VOCdevkit/VOC2012/JPEGImages/\n","!ls -l | grep ^- | wc -l"],"metadata":{"id":"FkQ9SIUNhpaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 디렉토리 생성 후 특정 포멧의 파일 리스트를 'images'로 바인딩\n","imageDir = \"/content/VOCdevkit/VOC2012/JPEGImages\"\n","images = [f for f in os.listdir(imageDir)\n","              if re.search(r'([a-zA-Z0-9\\s_\\\\.\\-\\(\\):])+(?i)(.jpg|.jpeg|.png)$', f)]        # 리눅스 정규식 표현 : 파일에 a-z,A-Z,0-9라 적혀있는 파일이면 모두 가져온다."],"metadata":{"id":"H_NDnznFhyQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training set, val set 분류 비율\n","ratio=0.1"],"metadata":{"id":"ymvpOVGBiJrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 세트 분류 및 확인\n","num_images = len(images)\n","num_test_images = math.ceil(ratio*num_images)\n","num_train_images = num_images - num_test_images\n","\n","print(\"num_images=\", num_images)\n","print(\"num_test_images=\", num_test_images)\n","print(\"num_train_images=\", num_train_images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzRoNS4ViF9t","executionInfo":{"status":"ok","timestamp":1679016155004,"user_tz":-540,"elapsed":5,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"4a7e7b1c-b5fb-4b9c-e487-6c2c876452cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num_images= 17125\n","num_test_images= 1713\n","num_train_images= 15412\n"]}]},{"cell_type":"code","source":["# 디렉토리 지정\n","train_dir = \"/content/train\"\n","test_dir = \"/content/test\""],"metadata":{"id":"36IMSXdsibi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pascal voc format dataset only\n","source = imageDir\n","copy_xml=True\n","sourceXML=\"/content/VOCdevkit/VOC2012/Annotations\"\n","# test set xml 파일 분류\n","for i in range(num_test_images):\n","  idx = random.randint(0, len(images)-1)\n","  filename = images[idx]\n","  copyfile(os.path.join(source, filename), os.path.join(test_dir, filename))\n","  if copy_xml:\n","    xml_filename = os.path.splitext(filename)[0]+'.xml'\n","    copyfile(os.path.join(sourceXML, xml_filename), os.path.join(test_dir,xml_filename))\n","\n","  images.remove(images[idx])"],"metadata":{"id":"2hiu0YKoigxQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test set 갯수 확인 (images * 2)\n","%%bash\n","cd \"/content/train\"\n","ls -l | grep ^- | wc -l"],"metadata":{"id":"ohrK6vUek75S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679016229760,"user_tz":-540,"elapsed":495,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"99419f8f-f60a-4075-ec49-a8c68eb829ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["30824\n"]}]},{"cell_type":"code","source":["# training set xml 파일 분류\n","for filename in images:\n","  copyfile(os.path.join(source, filename), os.path.join(train_dir, filename))\n","  if copy_xml:\n","    xml_filename = os.path.splitext(filename)[0]+'.xml'\n","    print(copyfile(os.path.join(sourceXML, xml_filename), os.path.join(train_dir, xml_filename)))"],"metadata":{"id":"AYUSz_Trkvtg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test set 갯수 확인 (images * 2)\n","%%bash\n","cd \"/content/test\"\n","ls -l | grep ^- | wc -l"],"metadata":{"id":"0ng4Mr-plLrm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OD_API 레이블 맵 복사\n","!cp \"/content/models/research/object_detection/data/pascal_label_map.pbtxt\" \\\n","\"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/annotations\""],"metadata":{"id":"_2Zh1_xylX7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 레이블 맵 이동 및 이름 변경\n","!mv \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/annotations/pascal_label_map.pbtxt\" \\\n","\"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/annotations/label_map.pbtxt\""],"metadata":{"id":"v9IKwjMRla46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 순서대로 record 파일, 이미지 파일, xml 파일 경로 지정 (pascal voc는 이미지와 xml의 경로가 같음)\n","output_path = \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations\"\n","image_dir = \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/images/train\"\n","xml_dir = \"/content\""],"metadata":{"id":"cKrrAbwBlx5u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train.record 파일 생성 명령어 (pascal voc는 이미지와 xml의 경로가 같음)\n","!python \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/scripts/preprocessing/make_tfrecord.py\" \\\n","-i \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/images/train\" \\\n","-l \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations/label_map.pbtxt\" \\\n","-o \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations/train.record\""],"metadata":{"id":"VDd-yiNhmefp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test.record 파일 생성 명령어\n","!python \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/scripts/preprocessing/make_tfrecord.py\" \\\n","-i \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/images/test\" \\\n","-l \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations/label_map.pbtxt\" \\\n","-o \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations/test.record\""],"metadata":{"id":"9sDUrlquohd5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["copyfile(\"/content/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\", \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/images/test/2007_000027.jpg\")"],"metadata":{"id":"XqSQWxeRgVks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 다운로드\n","%cd /content\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz"],"metadata":{"id":"PVvOyYjpoolq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/pre-trained-models/efficientdet_d1_coco17_tpu-32/pipeline.config -P /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3/pipeline.config"],"metadata":{"id":"hcM0R__wiYRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델을 해당 경로에 묶음 해제\n","!tar xvfzp \"/content/efficientdet_d1_coco17_tpu-32.tar.gz\" \\\n","-C \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/pre-trained-models\""],"metadata":{"id":"aLR3thivor-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델을 트레이닝할 디렉토리 생성\n","!mkdir \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3\"\n","!mkdir \"/content/gdrive/MyDrive/TF_OD_API/faster_rcnn_resnet50_v1/workspace/training_demo/exported-models/saved_efficientdet_d3\""],"metadata":{"id":"Y7NWkrhao6Ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train set 학습\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","--model_dir=\"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3\" \\\n","--pipeline_config_path=\"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3/pipeline.config\""],"metadata":{"id":"7qEWCBOfpQ-W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test set 학습\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","--model_dir=\"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3\" \\\n","--pipeline_config_path=\"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3/pipeline.config\" \\\n","--checkpoint_dir=\"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models\""],"metadata":{"id":"rTecir7RpQui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train set 저장\n","!python /content/models/research/object_detection/exporter_main_v2.py \\\n","--input_type image_tensor \\\n","--pipeline_config_path \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3/pipeline.config\" \\\n","--trained_checkpoint_dir \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/models/myft_efficientdet_d3\" \\\n","--output_directory \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models\""],"metadata":{"id":"DGtv94eTpwBc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679041834209,"user_tz":-540,"elapsed":145544,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"9824f12b-c3b2-4271-e9f1-e0c4625006a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-17 08:28:07.879082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-17 08:28:07.879189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-03-17 08:28:07.879210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-03-17 08:28:12.142386: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","I0317 08:28:12.165784 139794795468608 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0317 08:28:12.165958 139794795468608 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n","I0317 08:28:12.166027 139794795468608 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n","I0317 08:28:12.170920 139794795468608 efficientnet_model.py:143] round_filter input=32 output=32\n","I0317 08:28:12.213602 139794795468608 efficientnet_model.py:143] round_filter input=32 output=32\n","I0317 08:28:12.213761 139794795468608 efficientnet_model.py:143] round_filter input=16 output=16\n","I0317 08:28:12.376666 139794795468608 efficientnet_model.py:143] round_filter input=16 output=16\n","I0317 08:28:12.376829 139794795468608 efficientnet_model.py:143] round_filter input=24 output=24\n","I0317 08:28:12.661051 139794795468608 efficientnet_model.py:143] round_filter input=24 output=24\n","I0317 08:28:12.661261 139794795468608 efficientnet_model.py:143] round_filter input=40 output=40\n","I0317 08:28:12.946977 139794795468608 efficientnet_model.py:143] round_filter input=40 output=40\n","I0317 08:28:12.947171 139794795468608 efficientnet_model.py:143] round_filter input=80 output=80\n","I0317 08:28:13.324665 139794795468608 efficientnet_model.py:143] round_filter input=80 output=80\n","I0317 08:28:13.324832 139794795468608 efficientnet_model.py:143] round_filter input=112 output=112\n","I0317 08:28:13.703885 139794795468608 efficientnet_model.py:143] round_filter input=112 output=112\n","I0317 08:28:13.704053 139794795468608 efficientnet_model.py:143] round_filter input=192 output=192\n","I0317 08:28:14.172090 139794795468608 efficientnet_model.py:143] round_filter input=192 output=192\n","I0317 08:28:14.172260 139794795468608 efficientnet_model.py:143] round_filter input=320 output=320\n","I0317 08:28:14.368715 139794795468608 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0317 08:28:14.414142 139794795468608 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","W0317 08:28:18.278556 139794795468608 deprecation.py:350] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0317 08:28:18.350021 139794795468608 deprecation.py:623] From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","I0317 08:28:23.673779 139794795468608 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","I0317 08:28:37.551619 139794795468608 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","I0317 08:28:47.976211 139794795468608 api.py:459] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f23504d52b0>, because it is not built.\n","W0317 08:28:53.575631 139794795468608 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f23504d52b0>, because it is not built.\n","W0317 08:29:52.053300 139794795468608 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 535). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models/saved_model/assets\n","I0317 08:30:23.230293 139794795468608 builder_impl.py:797] Assets written to: /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models/pipeline.config\n","I0317 08:30:27.864517 139794795468608 config_util.py:253] Writing pipeline config file to /content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models/pipeline.config\n"]}]},{"cell_type":"code","source":["import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import ops as utils_ops\n","\n","%matplotlib inline"],"metadata":{"id":"WrG86T33vVwb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bbox 시각화 전처리\n","PATH_TO_MODEL_DIR = \"/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models\"\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","print(PATH_TO_SAVED_MODEL)"],"metadata":{"id":"dwgW1Bi-qG9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679042197747,"user_tz":-540,"elapsed":467,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"05e682ae-cfec-40c4-8973-501dd8856424"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/exported-models/saved_model\n"]}]},{"cell_type":"code","source":["PATH_TO_LABELS = '/content/gdrive/MyDrive/Team.B_Project/tf_efficientdet_lite/workspace/training_demo/annotations/label_map.pbtxt'\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"metadata":{"id":"EK00tLe-vmog"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# bbox 시각화 전처리\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# Load saved model and build the detection function\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"],"metadata":{"id":"pTUFJIJFqL5J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679042229166,"user_tz":-540,"elapsed":29888,"user":{"displayName":"최현빈","userId":"18077309965622897468"}},"outputId":"b7ff1a23-7952-4209-ecf2-29ce59ec7f9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model...Done! Took 29.579161882400513 seconds\n"]}]},{"cell_type":"code","source":["# 실질적인 bbox 시각화\n","IMAGE_PATHS_SELS=[\"/content/models/s01004453.jpg\"]\n","\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","\n","    Args:\n","      path: the file path to the image\n","\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","for image_path in IMAGE_PATHS_SELS:\n","\n","    print('Running inference for {}... '.format(image_path), end='')\n","\n","    # image_path = TEST_IMAGE_PATH + image_path\n","    image_np = load_image_into_numpy_array(image_path)\n","    \n","    # Things to try:\n","    # Flip horizontally\n","    # image_np = np.fliplr(image_np).copy()\n","\n","    # Convert image to grayscale\n","    # image_np = np.tile(\n","    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n","\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image_np)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis, ...]\n","    input_tensor = input_tensor[..., :3]\n","\n","    # input_tensor = np.expand_dims(image_np, 0)\n","    detections = detect_fn(input_tensor)\n","\n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(detections.pop('num_detections'))\n","    detections = {key: value[0, :num_detections].numpy()\n","                   for key, value in detections.items()}\n","    detections['num_detections'] = num_detections\n","\n","    # detection_classes should be ints.\n","    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","    image_np_with_detections = image_np.copy()[..., :3]\n","\n","    viz_utils.visualize_boxes_and_labels_on_image_array(\n","          image_np_with_detections,\n","          detections['detection_boxes'],\n","          detections['detection_classes'],\n","          detections['detection_scores'],\n","          category_index,\n","          use_normalized_coordinates=True,\n","          max_boxes_to_draw=200,\n","          min_score_thresh=.10,\n","          agnostic_mode=False)\n","\n","    plt.figure(figsize=(15,15))\n","    plt.imshow(image_np_with_detections)\n","    print('Done')\n","\n","plt.show()"],"metadata":{"id":"kd04AT_DqSlF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import glob\n","import pandas as pd\n","import csv\n","\n","def xml_to_csv():\n","    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n","    them in a single Pandas dataframe.\n","\n","    Parameters:\n","    ----------\n","    path : str\n","        The path containing the .xml files\n","    Returns\n","    -------\n","    Pandas DataFrame\n","        The produced dataframe\n","    \"\"\"\n","\n","    xml_list = []\n","    for xml_file in glob.glob(\"/content/train\" + '/*.xml'):\n","        tree = ET.parse(xml_file)\n","        root = tree.getroot()\n","        filename = root.find('filename').text\n","        width = int(root.find('size').find('width').text)\n","        height = int(root.find('size').find('height').text)\n","        for member in root.findall('object'):\n","            bndbox = member.find('bndbox')\n","            xminf = float(bndbox.find('xmin').text)\n","            yminf = float(bndbox.find('ymin').text)\n","            xmaxf = float(bndbox.find('xmax').text)\n","            ymaxf = float(bndbox.find('ymax').text)\n","            value = (filename,\n","                     width,\n","                     height,\n","                     member.find('name').text,\n","                     int(xminf),\n","                     int(yminf),\n","                     int(xmaxf),\n","                     int(ymaxf)                    \n","                     )\n","            xml_list.append(value)\n","    column_name = ['filename', 'width', 'height',\n","                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","\n","    return xml_df\n","\n","def main():\n","    for directory in ['pascal_train']:\n","        csv_df = xml_to_csv()\n","        csv_df.to_csv('/content/{}_labels.csv'.format(directory), index=None)\n","        print('Successfully converted json to csv.')\n","\n","main()"],"metadata":{"id":"RzX27OChJ148"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def json_to_csv():\n","    path_to_json = '/content/json'\n","    json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n","    path_to_jpeg = '/content/jpg'\n","    jpeg_files = [pos_jpeg for pos_jpeg in os.listdir(path_to_jpeg) if pos_jpeg.endswith('.jpg')]\n","    fjpeg=(list(reversed(jpeg_files)))\n","    csv_list = []\n","    labels=[]\n","    for j in json_files:\n","        with open('/content/json/{}'.format(j), encoding='utf-8') as data_file:\n","            data = json.load(data_file)\n","            width,height=data['image'][\"imsize\"][0],data['image'][\"imsize\"][0]\n","            for item in data[\"annotation\"]:\n","                box = item[\"box\"]\n","                if item[\"class\"]!='None':\n","                    name=item[\"class\"]\n","                    # labels.append(name)\n","                    xmin=box[0]\n","                    ymin=box[1]\n","                    xmax=box[2]\n","                    ymax=box[3]\n","                    value = (fjpeg,\n","                             width,\n","                             height,\n","                             name,\n","                             xmin,\n","                             ymin,\n","                             xmax,\n","                             ymax\n","                             )\n","                    csv_list.append(value)\n","    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","    csv_df = pd.DataFrame(csv_list, columns=column_name)\n","    # labels_train=list(set(labels))\n","    # with open(\"train_labels.csv\", \"wb\") as fp:   #Pickling\n","    #     pickle.dump(labels_train, fp)\n","    # return csv_df\n","\n","def main():\n","    for directory in ['train']:\n","        csv_df = json_to_csv()\n","        csv_df.to_csv('/content/{}_labels.csv'.format(directory), index=None)\n","        print('Successfully converted json to csv.')\n","\n","main()"],"metadata":{"id":"ewsac18BP0VN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import csv\n","\n","folder_path = \"/Users/yuyeon/Downloads/공공데이터/2D Object Detection/labels_class_5\"\n","save_folder_path = \"/Users/yuyeon/Downloads/공공데이터/2D Object Detection\"\n","csv_file_path = os.path.join(save_folder_path, \"labels_class_5.csv\")\n","csv_data = []\n","\n","for filename in os.listdir(folder_path):\n","    \n","    if filename.endswith(\".txt\"):\n","    \n","        txt_file_path = os.path.join(folder_path, filename)\n","        \n","        with open(txt_file_path, \"r\") as txt_file:\n","            \n","            for line in txt_file:\n","                \n","                data = line.strip().split()\n","                csv_data.append([filename[:-4] + \".jpg\", data[4], data[0], data[1], data[2], data[3]])\n","    \n","with open(csv_file_path, \"w\", newline=\"\") as csv_file:\n","    writer = csv.writer(csv_file)\n","    writer.writerow([\"filename\", \"class\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n","    writer.writerows(csv_data)"],"metadata":{"id":"E4-Ypdigqt1x"},"execution_count":null,"outputs":[]}]}